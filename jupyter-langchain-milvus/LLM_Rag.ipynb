{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pViAbjuYASA9"
   },
   "source": [
    "# ITS Support Chatbot\n",
    "\n",
    "This chatbot is an educational tool that's built to answer questions related to the CSUSB's [Information Technology Services](https://www.csusb.edu/its).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milvus Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries for the chatbot\n",
    "# Operating system interface for file/directory operations\n",
    "import os\n",
    "# Milvus database connection and utility functions\n",
    "from pymilvus import connections, utility\n",
    "# LangChain component for combining multiple documents into one context\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# Base document class for storing text and metadata\n",
    "from langchain.schema import Document\n",
    "# Template system for creating chat prompts\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# Groq's language model interface\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "# Milvus vector database integration for LangChain\n",
    "from langchain_milvus import Milvus\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "# Tool for downloading web pages recursively\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "# Library for parsing HTML content\n",
    "from bs4 import BeautifulSoup\n",
    "# Tool for splitting text into smaller chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Component for creating document retrieval systems\n",
    "from langchain.chains import create_retrieval_chain\n",
    "# Interface for HuggingFace's embedding models\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import pymilvus;\n",
    "\n",
    "# Define constant values used throughout the program\n",
    "# URL of the website we'll use as our knowledge base\n",
    "WEBSITE_URL = 'https://www.csusb.edu/its'\n",
    "# Path where we'll store our vector database files\n",
    "DATABASE_PATH = \"milvus/jupyter_milvus_vector3.db\"\n",
    "# Name of the embedding model we'll use to convert text to vectors\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "\n",
    "\n",
    "def vector_store_check(uri):\n",
    "    \"\"\"\n",
    "    Returns response on whether the vector storage exists\n",
    "\n",
    "    Returns:\n",
    "        boolean\n",
    "    \"\"\"\n",
    "    # Create the directory if it does not exist\n",
    "    head = os.path.split(uri)\n",
    "    os.makedirs(head[0], exist_ok=True)\n",
    "\n",
    "    # Connect to the Milvus database\n",
    "    connections.connect(\"default\", uri=uri)\n",
    "\n",
    "    # Return True if exists, False otherwise\n",
    "    return utility.has_collection(\"IT_support\")\n",
    "\n",
    "print(\"Function `vector_store_check` defined.\")\n",
    "\n",
    "def load_existing_db(uri=DATABASE_PATH):\n",
    "    \"\"\"\n",
    "    Load an existing vector store from the local Milvus database specified by the URI.\n",
    "\n",
    "    Args:\n",
    "        uri (str, optional): Path to the local milvus db. Defaults to DATABASE_PATH.\n",
    "\n",
    "    Returns:\n",
    "        vector_store: The vector store created\n",
    "    \"\"\"\n",
    "    # Load an existing vector store\n",
    "    vector_store = Milvus(\n",
    "        collection_name=\"IT_support\",\n",
    "        embedding_function=get_embedding_function(),\n",
    "        connection_args={\"uri\": uri},\n",
    "        index_params={\"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\", \"params\": {\"nlist\": 128}},  # Override default index\n",
    "                        \n",
    "    )\n",
    "    print(\"Vector store loaded\")\n",
    "    return vector_store\n",
    "\n",
    "print(\"Function `load_existing_db` defined.\")\n",
    "\n",
    "def get_embedding_function():\n",
    "    \"\"\"\n",
    "    Returns embedding function for the model\n",
    "\n",
    "    Returns:\n",
    "        embedding function\n",
    "    \"\"\"\n",
    "    embedding_function = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "    return embedding_function\n",
    "\n",
    "print(\"Function `get_embedding_function` defined.\")\n",
    "\n",
    "def load_documents_from_web():\n",
    "    \"\"\"\n",
    "    Load the documents from the web and store the page contents\n",
    "\n",
    "    Returns:\n",
    "        list: The documents loaded from the web\n",
    "    \"\"\"\n",
    "    loader = RecursiveUrlLoader(\n",
    "        url=DATABASE_PATH,\n",
    "        prevent_outside=True,\n",
    "        base_url=DATABASE_PATH\n",
    "        )\n",
    "    raw_documents = loader.load()\n",
    "\n",
    "    # Ensure documents are cleaned\n",
    "    cleaned_documents = []\n",
    "    for doc in raw_documents:\n",
    "        cleaned_text = clean_text_from_html(doc.page_content)\n",
    "        cleaned_documents.append(Document(page_content=cleaned_text, metadata=doc.metadata))\n",
    "\n",
    "    return cleaned_documents\n",
    "\n",
    "print(\"Function `load_documents_from_web` defined.\")\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split the documents into chunks\n",
    "\n",
    "    Args:\n",
    "        documents (list): The documents to split\n",
    "\n",
    "    Returns:\n",
    "        list: list of chunks of documents\n",
    "    \"\"\"\n",
    "    # Create a text splitter to split the documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=300,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    # Split the documents into chunks\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(\"Documents successfully split\")\n",
    "    return docs\n",
    "\n",
    "print(\"Function `split_documents` defined.\")\n",
    "\n",
    "def create_vector_store(docs, embeddings, uri):\n",
    "    \"\"\"\n",
    "    This function initializes a vector store using the provided documents and embeddings.\n",
    "\n",
    "    Args:\n",
    "        docs (list): A list of documents to be stored in the vector store.\n",
    "        embeddings : A function or model that generates embeddings for the documents.\n",
    "        uri (str): Path to the local milvus db\n",
    "\n",
    "    Returns:\n",
    "        vector_store: The vector store created\n",
    "    \"\"\"\n",
    "    # Create a new vector store and drop any existing one\n",
    "    vector_store = Milvus.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"IT_support\",\n",
    "        connection_args={\"uri\": uri},\n",
    "        drop_old=True,\n",
    "        index_params={\"index_type\": \"IVF_FLAT\", \"metric_type\": \"L2\", \"params\": {\"nlist\": 128}},  # Override default index\n",
    "\n",
    "    )\n",
    "\n",
    "    print(\"Vector store created\")\n",
    "    return vector_store\n",
    "\n",
    "print(\"Function `create_vector_store` defined.\")\n",
    "\n",
    "def initialize_milvus(uri: str=DATABASE_PATH):\n",
    "    print(pymilvus.__version__)\n",
    "    \"\"\"\n",
    "    Initialize the vector store for the RAG model\n",
    "\n",
    "    Args:\n",
    "        uri (str, optional): Path to the local vector storage. Defaults to DATABASE_PATH.\n",
    "\n",
    "    Returns:\n",
    "        vector_store: The vector store created\n",
    "    \"\"\"\n",
    "    if vector_store_check(uri):\n",
    "        vector_store = load_existing_db(uri)\n",
    "        print(\"Embeddings loaded from existing storage\")\n",
    "    else:\n",
    "        embeddings = get_embedding_function()\n",
    "        print(\"Embeddings Loaded\")\n",
    "        documents = load_documents_from_web()\n",
    "        print(\"Documents Loaded\")\n",
    "\n",
    "        # Split the documents into chunks\n",
    "        docs = split_documents(documents=documents)\n",
    "        print(\"Documents Splitting completed\")\n",
    "\n",
    "        vector_store = create_vector_store(docs, embeddings, uri)\n",
    "    print(\"Milvus successfully initialized\")\n",
    "    return vector_store\n",
    "\n",
    "print(\"Function `initialize_milvus` defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    initialize_milvus();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if this file is being run directly (not imported)\n",
    "if __name__ == \"__main__\":\n",
    "    # Start the main program\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
